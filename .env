# BMO Assistant Environment Configuration

# ===================
# Ollama Configuration (REQUIRED)
# ===================

# Ollama Model - Choose a small, fast model
# Recommended models:
#   llama3.2:1b    - Ultra fast, 1B parameters (RECOMMENDED for speed)
#   phi3:mini      - Very good quality, 3.8B parameters
#   gemma2:2b      - Fast and capable, 2B parameters
#   qwen2.5:0.5b   - Fastest option, 0.5B parameters
#   llama3.2:3b    - Good balance, 3B parameters

OLLAMA_MODEL=llama3.2:1b

# Ollama server URL (default for Docker)
OLLAMA_BASE_URL=http://ollama:11434

# Note: No API keys needed! Ollama runs locally and is 100% free

# ===================
# Google Cloud (Optional - for voice features)
# ===================

# Google Cloud credentials for Speech API
# Download JSON from: https://console.cloud.google.com/
# Place the file as 'credentials.json' in the root directory
# If you don't need voice features, you can skip this

# ===================
# Service URLs
# ===================

# For Docker deployment (default)
AI_SERVICE_URL=http://ai-service:8001
VOICE_SERVICE_URL=http://voice-service:8002
TASK_SERVICE_URL=http://task-service:8003

# For local development (uncomment and use these instead)
# AI_SERVICE_URL=http://localhost:8001
# VOICE_SERVICE_URL=http://localhost:8002
# TASK_SERVICE_URL=http://localhost:8003

# ===================
# Database
# ===================

REDIS_URL=redis://redis:6379

# ===================
# Frontend Configuration
# ===================

# For web interface
REACT_APP_API_URL=http://localhost:8000

# For mobile (replace with your server IP)
# Example: REACT_APP_API_URL=http://192.168.1.100:8000
# REACT_APP_API_URL=http://YOUR_SERVER_IP:8000

# ===================
# Optional: Advanced Settings
# ===================

# Redis expiry (seconds)
REDIS_EXPIRY=604800

# Max conversation history
MAX_HISTORY_MESSAGES=6

# Response timeout (seconds)
RESPONSE_TIMEOUT=30
